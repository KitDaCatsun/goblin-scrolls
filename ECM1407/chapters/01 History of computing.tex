\chapter{History of computing}

\section{Mechanical Machines}
\subsection{Pre-history}
\begin{itemize}
    \item Abacus: \(1000 - 500\) BC
    \item Antikythera mechanism: \(\approx100\) BC
\end{itemize}
The Antikythera mechanically calculated the position of astronomical objects.
\begin{itemize}
    \item Wilhelm Schickard's calculator: 1623
    \item Leibniz's calculating machine: 1640
\end{itemize}

\subsection{Charles Babbage}
In 1821, Charles Babbage wanted to run calculations for numerical tables using steam. With help from John Herschel, Babbage designed his difference engine in one year and announced it to the public. In 1823 he received Â£1,700 from the government to start working on his project.

Babbage hired the toolmaker Joseph Clement to help him build Difference Engine No. 1. It takes ten years to complete the first functional prototype. In 1834 construction is halted due to disputes between Clement and Babbage over money.

The machine could do a series of calculations on a number of variables, and had storage that could be used for later processing.

In 1837 Babbage described a general-purpose programmable machine that he called the analytical engine. This was a machine that could be programmed with and execute an arbitrary program. The machine would use the process:
\begin{enumerate}
    \item Input
    \item Store
    \item Mill
    \item Output
\end{enumerate}
But the analytical engine was never built due to a lack of funding.

From 1847 to 1849 Babbage developed the Difference Engine No. 2. This machine, and his previous designs, have been built and shown to work in recent history.

In 1833 Babbage met Ada Lovelace. In 1834, Lovelace translated a paper by Luigi Mendabrea. She adds a number of notes to the paper, including `Note G', which described how an analytical engine could be used to generate bernoulli numbers. This is considered to be the first computer program.

Although mechanical, Babbage's machines functioned digitally on base 10.

\section{Numeral systems}
In base 10, each position represents increasing powers of 10: \(10^0, 10^1, 10^2, \dots, 10^n\). This pattern follows for binary (base 2).

Wilhelm Leibniz described how mathematics can be done using binary in 1703. He also developed the concept of formal symbolic logic.

Charles Boole developed the concept of using symbols to represent objects in 1847. These symbols obeyed algebraic laws and could be added and multiplied like real numbers. The etymology `Boolean' comes from Boole.

In 1936 Claude Shannon provided mathematical techniques to build a network of switches that realized a specific logical function\footnote{This was done as his master's thesis.}.

\section{Electronic machines}

\begin{table}[htbp]
    \centering
    \begin{tabular}{ccc}
        \toprule
        \textbf{Generation} & \textbf{Time} & \textbf{Technology} \\
        \midrule
        First               & 1950 - 1959   & Vacuum tubes        \\
        Second              & 1960 - 1968   & Transistors         \\
        Third               & 1969 - 1977   & Integrated circuits \\
        Fourth              & 1978 - 2009   & Microprocessor      \\
        Fifth               & 2010 -        & ?                   \\
        \bottomrule
    \end{tabular}
    \caption{Generations of Electronic Computers}
    \label{tab:electronic_generations}
\end{table}

\subsection{Vacuum tubes}
Vacuum tubes have problems with heat, weight, size, and reliability.

\subsection{Transistors}
Transistors enable the creation of logic gates without losses due to heat.

The IBM System 360 introduced the concept of a computer family. Machines could be upgraded without loosing compatibility.

\subsection{Integrated Circuits}
An integrated circuit (IC) combines millions of transistors into one small, cheap, and reliable unit.

The first commerical supercomputer was the Cray-1.

\subsection{Microprocessor}
In 1971 Intel\footnote{Then Integrated Electronics.} developed the first commercially available microprocessor.

The IBM PC was the first to use an open architecture so that other companies could develop peripherals and components.

\subsection{Modern Era}
There are various ideas of what technology defines the current generation of computing. These include the post PC era, Artificial Intelligence, system on a chip (SoC) where one IC implements most components of a computer.
